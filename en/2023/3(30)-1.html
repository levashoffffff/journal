<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
	<title>SEMANTIC TEXT ANALYSIS USING ARTIFICIAL NEURAL NETWORKS BASED ON NEURAL-LIKE ELEMENTS WITH TEMPORAL SIGNAL SUMMATION</title>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8"> 
	<meta name = "description" content = "Problems of Artificial Intelligence №2023'3(30)">
 	<meta name="Keywords" content="Problems of artificial intelligence No.2023'3(30), Problems of artificial intelligence, international peer-reviewed scientific and theoretical journal, DNR, 
                                   scientific journal, State Institution Institute of Artificial Intelligence Problems, GU IPII"> 

 	
 	<meta name = "robots" content = "index,follow">
	
	<link href="../../style_pai.css" rel="stylesheet" type="text/css">	
	<link rel="SHORTCUT ICON" href="../../image_pai/favicon.ico" type="image/x-icon">	

    <script src="../../javascript.js"></script>



                <link rel="schema.DC" href="https://purl.org/dc/elements/1.1/"/>
                                <meta name="keywords" content="text analysis, language model, neural network, transformer model, semantic analysis of texts, artificial neural networks based on neurons with temporal summation of signals, language levels, semantic level, TextAnalyst technology for semantic text analysis, applications, семантический анализ текстов, искусственные нейронные сети на основе нейронов с временным суммированием сигналов, языковые уровни, семантический уровень, языковая модель, нейронная сеть, трансформаторная модель, технология TextAnalyst для семантического анализа текстов, приложени"/>
                                  <meta name="description" content="Text as an image is analyzed in the human visual analyzer. In this case, the image is scanned along the points of the greatest informativity, which are the inflections of the contours of the equitextural areas, into which the image is roughly divided. In the case of text analysis, individual characters of the alphabet are analyzed in this wayNext, the text is analyzed as repetitive language elements of varying complexity. Dictionaries of level-forming elements of varying complexity are formed, the top of which is the level of acceptable com-patibility of the root stems of words (names) in sentences of the text, that is, the semantic level. The level of semantics represented by pairs of root stems is virtually a homo geneous directed semantic network. Re-ranking the weights of the network vertices corresponding to the root stems of individual names, as occurs in the hippocampus, makes it possible to move from the frequency characteristics of the network to their semantic weights. Such networks can be used to analyze texts that represent them: one can compare them with each other, classify and use to identify the most significant parts of texts (generate abstracts of texts), etc."/>
                                  <meta name="DC.Subject" content="text analysis"/>
                                  <meta name="DC.Subject" content="language model"/>
                                  <meta name="DC.Subject" content="neural network"/>
                                  <meta name="DC.Subject" content="transformer model"/>
                                  <meta name="DC.Subject" content="semantic analysis of texts"/>
                                  <meta name="DC.Subject" content="artificial neural networks based on neurons with temporal summation of signals"/>
                                  <meta name="DC.Subject" content="language levels"/>
                                  <meta name="DC.Subject" content="semantic level"/>
                                  <meta name="DC.Subject" content="TextAnalyst technology for semantic text analysis"/>
                                  <meta name="DC.Subject" content="applications"/>
                                  <meta name="DC.Subject" content="семантический анализ текстов"/>
                                  <meta name="DC.Subject" content="искусственные нейронные сети на основе нейронов с временным суммированием сигналов"/>
                                  <meta name="DC.Subject" content="языковые уровни"/>
                                  <meta name="DC.Subject" content="семантический уровень"/>
                                  <meta name="DC.Subject" content="языковая модель"/>
                                  <meta name="DC.Subject" content="нейронная сеть"/>
                                  <meta name="DC.Subject" content="трансформаторная модель"/>
                                  <meta name="DC.Subject" content="технология TextAnalyst для семантического анализа текстов"/>
                                  <meta name="DC.Subject" content="приложени"/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;en&quot;" content="Kharlamov, A."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;en&quot;" content="Samaev, E."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;en&quot;" content="Kuznetsov, D."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;en&quot;" content="Pantiukhin, D."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;ru&quot;" content="Харламов, А."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;ru&quot;" content="Самаев, Е."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;ru&quot;" content="Кузнецов, Д."/>
                                  <meta name="DC.Creator.PersonalName" xml="lang=&quot;ru&quot;" content="Пантюхин, Д."/>
                                  <meta name="DC.Description" xml="lang=&quot;en&quot;" content="Text as an image is analyzed in the human visual analyzer. In this case, the image is scanned along the points of the greatest informativity, which are the inflections of the contours of the equitextural areas, into which the image is roughly divided. In the case of text analysis, individual characters of the alphabet are analyzed in this wayNext, the text is analyzed as repetitive language elements of varying complexity. Dictionaries of level-forming elements of varying complexity are formed, the top of which is the level of acceptable com-patibility of the root stems of words (names) in sentences of the text, that is, the semantic level. The level of semantics represented by pairs of root stems is virtually a homo geneous directed semantic network. Re-ranking the weights of the network vertices corresponding to the root stems of individual names, as occurs in the hippocampus, makes it possible to move from the frequency characteristics of the network to their semantic weights. Such networks can be used to analyze texts that represent them: one can compare them with each other, classify and use to identify the most significant parts of texts (generate abstracts of texts), etc."/>
                                  <meta name="DC.Description" xml="lang=&quot;ru&quot;" content="Текст как изображение анализируется в зрительном анализаторе человека. При этом изобра же ние сканируется по точкам наибольшей информативности, которые являются перегибами контуров эквитекстурных областей, на которые грубо разбивается изображение. В случае анализа текста таким образом анализируются отдельные символы алфавита. Далее текст анализируется как повторяющиеся элементы языка различной сложности. Формируются словари уровнеобразующих элементов различной сложности, вершиной которых является уровень допустимой соче тае мо сти корневых основ слов (имен) в предложениях текста, то есть семантический уровень. Уровень семантики, представленный парами корневых основ, представляет собой однородную направ лен ную семантическую сеть. Переранжирование весов вершин сети, соответствующих корне вым корням отдельных имен, как это происходит в гиппокампе, позволяет перейти от частотных ха рактеристик сети к их семантическим весам. Такие сети можно использовать для анализа текстов, которые их представляют: сравнивать их между собой, классифицировать и исполь зо вать для выявления наиболее значимых частей текстов (генерировать рефераты текстов) и подобное."/>
                                  <meta name="DC.Source" content="Проблемы искусственного интеллекта"/>
                                  <meta name="DC.Title" xml="lang=&quot;en&quot;" content="SEMANTIC TEXT ANALYSIS USING ARTIFICIAL NEURAL NETWORKS BASED ON NEURAL-LIKE ELEMENTS WITH TEMPORAL SIGNAL SUMMATION"/>
                                  <meta name="DC.Title" xml="lang=&quot;ru&quot;" content="СЕМАНТИЧЕСКИЙ АНАЛИЗ ТЕКСТА С ИСПОЛЬЗОВАНИЕМ ИСКУССТВЕННЫХ НЕЙРОННЫХ СЕТЕЙ НА ОСНОВЕ НЕЙРОПОДОБНЫХ ЭЛЕМЕНТОВ С ВРЕМЕННЫМ СУММИРОВАНИЕМ СИГНАЛОВ"/>
                                  <meta name="DC.Date.issued" content="2023-12-19"/>
                                  <meta name="DC.Identifier.pageNumber" content=""/>
                                  <meta name="DC.Identifier.DOI" content="10.34757/2413-7383.2023.30.3.001"/>
                                  <meta name="DC.Identifier.URI" content=""/>
                                  <meta name="DC.Identifier.Rights" content=""/>
                                  <meta name="DC.Identifier.Rights" content=""/>
                                  <meta name="DC.Source.ISSN" content="2413-7383"/>
                                  <meta name="citation_title" content="SEMANTIC TEXT ANALYSIS USING ARTIFICIAL NEURAL NETWORKS BASED ON NEURAL-LIKE ELEMENTS WITH TEMPORAL SIGNAL SUMMATION"/>
                                  <meta name="citation_publication_date" content="2023/12/19"/>
                                  <meta name="citation_journal_title" content="Проблемы искусственного интеллекта"/>
                                  <meta name="citation_doi" content="10.34757/2413-7383.2023.30.3.001"/>
                                  <meta name="citation_issn" content="2413-7383"/>
                                  <meta name="citation_pdf_url" content=""/>
                                  <meta name="citation_pages" content=""/>
                                  <meta name="citation_issue" content="№ 3 (30)"/>
                                  <meta name="citation_author" content="Kharlamov, A."/>
                                  <meta name="citation_author" content="Samaev, E."/>
                                  <meta name="citation_author" content="Kuznetsov, D."/>
                                  <meta name="citation_author" content="Pantiukhin, D."/>
                                  <meta name="DC.Type" content="Text.Serial.Journal"/>



<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
   (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
   var z = null;m[i].l=1*new Date();
   for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}
   k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
   (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

   ym(90090525, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
   });
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/90090525" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
<!-- /Yandex.Metrika counter -->

</head>

<body >

<!-- Rating Mail.ru counter -->
<script type="text/javascript">
var _tmr = window._tmr || (window._tmr = []);
_tmr.push({id: "3259293", type: "pageView", start: (new Date()).getTime()});
(function (d, w, id) {
  if (d.getElementById(id)) return;
  var ts = d.createElement("script"); ts.type = "text/javascript"; ts.async = true; ts.id = id;
  ts.src = "https://top-fwz1.mail.ru/js/code.js";
  var f = function () {var s = d.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ts, s);};
  if (w.opera == "[object Opera]") { d.addEventListener("DOMContentLoaded", f, false); } else { f(); }
})(document, window, "topmailru-code");
</script><noscript><div>
<img src="https://top-fwz1.mail.ru/counter?id=3259293;js=na" style="border:0;position:absolute;left:-9999px;" alt="Top.Mail.Ru" />
</div></noscript>
<!-- //Rating Mail.ru counter -->



<table  >
<tr>
    <td rowspan="3" valign="top" width="200px"  height="225px"><a href="../news.html" ><img src="../../image_pai/logo.jpg"  alt="Логотип" class="logo" border="0"></a></td>
    <td colspan="2"  align="right"  height="104px" ><img src="../../image_pai/top_en.jpg"  border="0"  ></td>
</tr>

<tr>
<td align="right"  valign="bottom" style="padding: 5px;">
<a href="../../ru/2023/3(30)-1.html"  class="language"><img src="../../image_pai/Russia.png" class="imgflag">РУС</a>
<a href="3(30)-1.html" class="language"><img src="../../image_pai/United-Kingdom.png" class="imgflag">ENG</a>
</td>

<td  align="right"    valign="bottom"   height="70px"  border="0">
	
	
</td>
</tr>

<tr>
<td  colspan="2" bgcolor="#ffffff">
<H1>SEMANTIC TEXT ANALYSIS USING ARTIFICIAL NEURAL NETWORKS BASED ON NEURAL-LIKE ELEMENTS WITH TEMPORAL SIGNAL SUMMATION</H1>
</td>
</tr>

<tr>
<td  bgcolor="#04005f"  align="right"  valign="top"   border="0">
	

<p class="rmenu">About </p>
	
	<a href="../news.html" class="Link menu">News  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../aims-and-scope.html" class="Link menu">Aims and Scope  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../founder-and-publisher.html" class="Link menu">Founder and Publisher  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../editorial-board.html" class="Link menu">Editorial board  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../licensing-terms.html" class="Link menu">Licensing terms  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../privacy-statement.html" class="Link menu">Privacy Statement  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../plagiarism-policy.html" class="Link menu">Plagiarism policy  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../publication-ethics.html" class="Link menu">Publication ethics  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../archiving.html" class="Link menu">Archiving Policy <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../subscription.html" class="Link menu">Subscription  <img src="../../image_pai/marker.jpg"  border="0"></a><br>

	<br>
	<br>
	<p class="rmenu">For Authors</p>
	
	<a href="../instructions.html" class="Link menu">Instructions for authors  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../reviewing-process.html" class="Link menu">Reviewing proccess  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../copyright-notice.html" class="Link menu">Copyright Notice  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../license-agreement.html" class="Link menu">License agreement  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<a href="../apc.html" class="Link menu">Article processing charges  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<br>
	<br>	


	<p class="rmenu">Archive</p>

	<a href="../archive.html" class="Link menu">All issues  <img src="../../image_pai/marker_on.jpg"  border="0"></a><br>
	<a href="../search.html" class="Link menu">Search  <img src="../../image_pai/marker.jpg"  border="0"></a><br>

	<br>
	<br>


	<p class="rmenu">Contacts</p>

	<a href="../contacts.html" class="Link menu">Contacts  <img src="../../image_pai/marker.jpg"  border="0"></a><br>
	<br>
	<br>

	
</td>





<td colspan="2" align="justify"    valign="top"  bgcolor="#ffffff">

<p ><b>Kharlamov Alexander </b> 
<br>Institute of Higher Nervous Activity and Neurophysiology, RAS, Moscow;
<br>Moscow State Linguistic University, Moscow
<br>HSE University, Moscow
<br>Moscow Institute of Physics and Technology, Moscow Region, RF
<br>Research interests: neuroinformatics, semantic representations, automatic text processing, integrated robots, physiology of sensory systems
</p>

<p ><b>Samaev Eugeniy</b> 
<br>NPP Garant-Service-Universitet, Moscow
</p>

<p ><b>Kuznetsov Dmitriy </b> 
<br>Positive Technologies, Moscow
</p>

<p ><b>Pantiukhin Dmitriy </b> 
<br>MIREA - Russian Technological University, Moscow
<br>Area of interest: neural network, neurocomputer, neuromorphic devices, memristor, information security, neural network management system, computer vision,  natural language processing
</p>


<p>
<a href="../../download_pai/2023_3/1_Харламов и ко.pdf" target="_blank"><button>Download pdf</button></a>
</p>
<p>
<b>UDC</b> 528.013<br>
<b>DOI</b> <a HREF="https://search.rads-doi.org/project/13749/object/201177">10.34757/2413-7383.2023.30.3.001</a><br>
<b>Language: </b> English<br>
</p>
<p>
<b>Annotation: </b>
Text as an image is analyzed in the human visual analyzer. In this case, the image is scanned along the points of the greatest informativity, which are the inflections of the contours of the equitextural areas, into which the image is roughly divided. In the case of text analysis, individual characters of the alphabet are analyzed in this wayNext, the text is analyzed as repetitive language elements of varying complexity. Dictionaries of level-forming elements of varying complexity are formed, the top of which is the level of acceptable com-patibility of the root stems of words (names) in sentences of the text, that is, the semantic level. The level of semantics represented by pairs of root stems is virtually a homo-geneous directed semantic network. Re-ranking the weights of the network vertices corresponding to the root stems of individual names, as occurs in the hippocampus, makes it possible to move from the frequency characteristics of the network to their semantic weights. Such networks can be used to analyze texts that represent them: one can compare them with each other, c lassify and use to identify the most significant parts of texts (generate abstracts of texts), etc.</p>
<p>
<b>Keywords:</b> text analysis; language model; neural network; transformer model; semantic analysis of texts; artificial neural networks based on neurons with temporal summation of signals; language levels; semantic level; TextAnalyst technology for semantic text analysis; applications.я.
</p>
<p>
<b>References:</b>
<br>1. Lena Voita. Language Modeling. // Available online: https://lena-voita.github.io/nlp_course/language_modeling (accessed on 20 June 2023). 
<br>2. Zhao, Wayne Xin, et al. "A survey of large language models." arXiv preprint arXiv:2303.18223 (2023). 
<br>3. Y. Zhu, R. Kiros, R. S. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler, “Aligning books and movies: Towards story-like visual explanations by watching movies and reading books,” in 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13, 2015. IEEE Computer Society, 2015, pp. 19–27 
<br>4. “Project Gutenberg.” [Online]. Available: https://www.gutenberg.org/ 5. “Wikipedia.” [Online]. Available: https://en.wikipedia.org/wiki/Main Page 
<br>6. A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al., “Language models are unsupervised multitask learners,” OpenAI blog, p. 9, 2019 
<br>7. A. Gokaslan, V. C. E. Pavlick, and S. Tellex, “Openwebtext corpus,” http://Skylion007.github.io/OpenWebTextCorpus, 2019. 
<br>8. J. Baumgartner, S. Zannettou, B. Keegan, M. Squire, and J. Blackburn, “The pushshift reddit dataset,” in Proceedings of the Fourteenth International AAAI Conference on Web and Social Media, ICWSM 2020, Held Virtually, Original Venue: Atlanta, Georgia, USA, June 8-11, 2020. AAAI Press, 2020, pp. 830– 839. 
<br>9. “Common crawl.” [Online]. Available: https://commoncrawl.org/ 
<br>10. L. Xue, N. Constant, A. Roberts, M. Kale, R. Al-Rfou, A. Siddhant, A. Barua, and C. Raffel, “mt5: A massively multilingual pre-trained text-to-text transformer,” in Proceedings of the 2021 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, 2021, pp.483–498.
<br>11.R. Zellers, A. Holtzman, H. Rashkin, Y. Bisk, A. Farhadi, F. Roesner, and Y. Choi, “Defending against neural fake news,” in Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alch´e Buc, E. B. Fox, and R. Garnett, Eds., 2019, pp. 9051–9062. 
<br>12. The Russian National Corpus (ruscorpora.ru). 2003—2023. 
<br>13. “Bigquery dataset.” [Online]. Available: https://cloud.google.com/bigquery?hl=zh-cn 
<br>14. Gaulton, A. et al. The ChEMBL database in 2017. Nucleic Acids Res. 45, D945–D954 (2017) 
<br>15. Merk, D., Friedrich, L., Grisoni, F. & Schneider, G. De novo design of bioactive small molecules by artificial intelligence. Mol. Inf. 37, 1700153 (2018). 
<br>16.Chip Huyen. Evaluation Metrics for Language Modeling \\ The Gradient. 2019 [Online]. Available: https://thegradient.pub/understanding-evaluation-metrics-for-language-models/ 
<br>17. Gu, Jiuxiang, et al. "Recent advances in convolutional neural networks." Pattern recognition 77 (2018): 354-377. 
<br>18. Dumoulin, Vincent, and Francesco Visin. "A guide to convolution arithmetic for deep learning." arXiv preprint arXiv:1603.07285 (2016). 
<br>19. Oord, Aaron van den, et al. "Wavenet: A generative model for raw audio." arXiv preprint arXiv:1609.03499 (2016). 
<br>20. Dauphin, Yann N., et al. "Language modeling with gated convolutional networks." International conference on machine learning. PMLR, 2017. 
<br>21. Staudemeyer, Ralf C., and Eric Rothstein Morris. "Understanding LSTM--a tutorial into long short-term memory recurrent neural networks." arXiv preprint arXiv:1909.09586 (2019). 
<br>22. Sepp; Hochreiter and J¨urgen Schmidhuber. Long Short-Term Memory. Neural computation, 9(8):1735– 1780, 1997. 
<br>23.Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. In arXiv, pages 1–9, dec 2014. 
<br>24. Sharma, Sagar, Simone Sharma, and Anidhya Athaiya. "Activation functions in neural networks." Towards Data Sci 6.12 (2017): 310-316. 
<br>25.Jozefowicz, R., Zaremba, W., & Sutskever, I. (2015, June). An empirical exploration of recurrent network architectures. In International conference on machine learning (pp. 2342-2350). PMLR. 
<br>26. Alex Graves and Jurgen Schmidhuber. Framewise phoneme classification with bidirectional LSTM networks. In Proc. of the Int. Joint Conf. on Neural Networks, volume 18, pages 2047–2052, Oxford, UK, UK, jun 2005. Elsevier Science Ltd. 
<br>27.Rae, Jack, et al. "Fast parametric learning with activation memorization." International Conference on Machine Learning. PMLR, 2018. 
<br>28. Grave, E., Joulin, A., and Usunier, N. Improving neural language models with a continuous cache. arXiv preprint arXiv:1612.04426, 2016b. 
<br>29.Bai, Shaojie, J. Zico Kolter, and Vladlen Koltun. "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling." arXiv preprint arXiv:1803.01271 (2018). 
<br>30. Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems 30 (2017). 
<br>31. Lin, Tianyang, et al. "A survey of transformers." AI Open (2022). 
<br>32. Kalyan, Katikapalli Subramanyam, Ajit Rajasekharan, and Sivanesan Sangeetha. "Ammus: A survey of transformer-based pretrained models in natural language processing." arXiv preprint arXiv:2108.05542 (2021). 
<br>33. Baevski, Alexei, and Michael Auli. "Adaptive input representations for neural language modeling." arXiv preprint arXiv:1809.10853 (2018). 
<br>34. Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). "BERT: Pretraining of Deep Bidirectional Transformers for Language Understanding". arXiv:1810.04805v2 
<br>35. Luo, Linkai, and Yue Wang. "Emotionx-hsu: Adopting pre-trained bert for emotion classification." arXiv preprint arXiv:1907.09669 (2019). 
<br>36.Radford, Alec, et al. "Language models are unsupervised multitask learners." OpenAI blog 1.8 (2019): 9. 
<br>37. Shoeybi, Mohammad, et al. "Megatron-lm: Training multi-billion parameter language models using model parallelism." arXiv preprint arXiv:1909.08053 (2019). 
<br>38.Ren, Xiaozhe; Zhou, Pingyi; Meng, Xinfan; Huang, Xinjing; Wang, Yadao; Wang, Weichao; Li, Pengfei; Zhang, Xiaoda; Podolskiy, Alexander; Arshinov, Grigory; Bout, Andrey; Piontkovskaya, Irina; Wei, Jiansheng; Jiang, Xin; Su, Teng; Liu, Qun; Yao, Jun (March 19, 2023). "PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing". arXiv:2303.10845 
<br>39.Dai, Andrew M; Du, Nan (December 9, 2021). "More Efficient In-Context Learning with GLaM". ai.googleblog.com. Retrieved 2023-03-09. 
<br>40. Dey, Nolan, et al. "Cerebras-GPT: Open compute-optimal language models trained on the Cerebras wafer-scale cluster." arXiv preprint arXiv:2304.03208 (2023). 
<br>41. Kharlamov A. A. Assotsiativnaya pamyat’ – sreda dlya formirovaniya prostranstva znanij. Ot biologii k prilozheniyam. [Associative memory as an environment for the formation of a space of knowledge. From biology to applications]. Dusseldorf, Germany: Palmarium Academic Publishing - 109 p. (in Russian) Available online: Ассоциативная память — среда для формирования пространства знаний: От биологии к приложениям (Russian Edition): Харламов, Александр: 9783639645491: Amazon.com: Books (accessed on 12 April 2017). 
<br>42. Neuroinformatics and Semantic Representations. Theory and Applications. Alexander Kharlamov & Maria Pilgun eds. 317 P. Cambridge Scholars Publishing. 2020. Available online: Neuroinformatics and Semantic Representations: Theory and Applications - Cambridge Scholars Publishing (accessed on 2020). 
<br>43.Rolls, E.T. Theoretical and Neurophysiological Analysis of the Functions of the Primate Hippocampus in Memory. In: Cold Spring Harbor Symposia on Quantitative Biology, Vol. LV, 1990, Cold Spring Harbor Laboratory Press. Pp. 995 – 1006. Available online: Dendritic organization in the neurons of the visual and motor cortices of the cat - PMC (nih.gov) (accessed on 1953). 
<br>44. Vinogradova O.S. Gippokamp i pamyat’. [Hippocampus and memory] Moscow: Nauka, 1975. - 336 p. (in Russian) Available online: Vinogradova, Okga Sergeevna – Gippokamp i pamyat’ [Текст] - Search RSL (accessed on 1975). 
<br>45. Hopfield, J.J. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl. Acad. Sci. 79, 1982. Pp. 2554 – 2558. Available online: Neural networks and physical systems with emergent collective computational abilities. - PMC (nih.gov) (accessed on 1982). 
<br>46.Buzikashvili N.E., Samoylov D.V., Krylova G.A. N-grammy v lingvistike. [N-grams in linguistics]// In Collection of papers: Methods and means of document management. Moscow: Editorial URRS. 2000. Pp. 91-130. (in Russian) Available online: Metody I sredstva raboty s dokumentami | | Editorial URSS | Knigi po reklame, marketingu, PR I dizayinu | Advertology.Ru (accessed on 2000). 
<br>47. Kharlamov A.A. Svidetelstvo o registratsii programmy “Programma dlya avtomaticheskogo smyslovogo analiza tekstov na osnove neyronnykh setey “TextAnalyst”” [Certificate of registration of the program "Program for automatic semantic text processing based on neural networks "TextAnalyst""]. Available online: ww.fips.ru/vse-servisy.php (accessed on 31 October 1997). 
<br>48. Kharlamov A.A. Sposob avtomatizirovannoj semanticheskoj indeksatsii teksta na estestvennom yazyke. [A method for automated semantic indexing of natural language text] Patent for invention No. 2518946, priority dated November 27, 2012. Registered April 11, 2014 (in Russian) Available online: A METHOD OF AUTOMATED SEMANTIC INDEXING OF TEXT IN NATURAL LANGUAGE. Patent No. RU 2518946 IPC G06F40/20 | Patent Exchange - Moscow Innovation Cluster (i.moscow) (accessed on 2014). 
<br>49.R-sistema. Vvedenie v ekonomicheskij shpionazh. Praktikum po ekonomicheskoj razvedke v sovremennom rossijskom predprinimatel’stve. [I-system. Introduction to economic espionage. Workshop on economic intelligence in modern Russian business] In 2 volumes. Moscow, Russia: “Hamtek Publisher”, 1997. (in Russian) Available online: Sergey Khich / R-system: introduction to economic espionage. Practicum on economic intelligence in modern Russian entrepreneurship. In 2 volumes. | Arbatkniga (arbatkniga.ru) (accessed on 1997). 
<br>50. Golenkov V.V., Gulyakina N.A. Printsipy postroeniya massovoj semanticheskoj tekhnologii komponentnogo proektirovaniya intellektualnykh sistem. [Principles of building a mass semantic technology of component design of intelligent systems] Proc. of the Conference “Open Semantic Technologies for Intelligent Systems” (OSTIS 2012). 2012. Pp. 23-24. (in Russian) Available online Golenkov_Printsipy.PDF (bsuir.by) (accessed on 2012). 
<br>51. Ivan Smirnov, Maksim Stankevich, Yulia Kuznetsova, Margarita Suvorova, Daniil Larionov, Elena Nikitina, Mikhail Savelov, and Oleg Grigoriev TITANIS: A Tool for Intelligent Text Analysis in Social Media. Springer Nature Switzerland AG 2021 S. M. Kovalev et al. (Eds.): RCAI 2021, LNAI 12948, pp. 232–247. 2021. Available online https://doi.org/10.1007/978-3-030-86855-0_16 (accessed on 2021)

</p>

<p>
<b>Issues: </b>3(30)'2023
<br>
<b>Section: </b>Informatics, Computer Engineering and Control
<br>
<b>Cite:</b>
Kharlamov, A. SEMANTIC TEXT ANALYSIS USING ARTIFICIAL NEURAL NETWORKS BASED ON NEURAL-LIKE ELEMENTS WITH TEMPORAL SIGNAL SUMMATION // A. Kharlamov, E. Samaev, D. Kuznetsov и др. // Проблемы искусственного интеллекта. - 2023. № 3 (30). - http://search.rads-doi.org/project/13749/object/201177 doi: 10.34757/2413-7383.2023.30.3.001
</p>





<br>   
<p><a href="3(30).html"><button>back to issues 3(30)'2023</button></a></p>
<br>

</td>



</tr>

<tr>
<td colspan="3"   height="236px"   class="tdbottom">
<br><img src="../../image_pai/bottom_1_en.jpg"  border="0">
<br>
<p class="footer"><a href="http://guiaidn.ru" target="_blank" class="footer menu">Founder and publisher: State Institution «Institute of Problems of Artificial Intelligence»</a></p>
<p class="footer">Address: 83048, Donetsk, Artema st.,118 </p>
<p class="footer">Telefon: +7 (856) 311-72-01</p>
<p class="footer">Editor-in-chief: V. Ju. Shelepov</p>

<p class="footer">
<!-- Yandex.Metrika informer -->
<a href="https://metrika.yandex.ru/stat/?id=90090525&amp;from=informer"
target="_blank" rel="nofollow"><img src="https://informer.yandex.ru/informer/90090525/3_0_2069A5FF_004985FF_1_pageviews"
style="width:88px; height:31px; border:0;" alt="Яндекс.Метрика" title="Яндекс.Метрика: данные за сегодня (просмотры, визиты и уникальные посетители)" class="ym-advanced-informer" data-cid="90090525" data-lang="ru" /></a>
<!-- /Yandex.Metrika informer -->

<!-- Rating Mail.ru logo -->
<a href="https://top.mail.ru/jump?from=3259293">
<img src="https://top-fwz1.mail.ru/counter?id=3259293;t=456;l=1" style="border:0;" height="31" width="88" alt="Top.Mail.Ru" /></a>
<!-- //Rating Mail.ru logo -->
</p>


<p class="footer">&copy; State Institution «Institute of Problems of Artificial Intelligence», </li>
<script>document.write(new Date().getFullYear());</script></p>
<br>
</tr>

</table>
</body >
</html>